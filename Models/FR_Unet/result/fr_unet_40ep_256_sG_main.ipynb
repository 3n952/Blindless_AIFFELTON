{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-01-28 09:09:11.068374: E external/local_xla/xla/stream_executor/cuda/cuda_dnn.cc:9261] Unable to register cuDNN factory: Attempting to register factory for plugin cuDNN when one has already been registered\n",
      "2024-01-28 09:09:11.068395: E external/local_xla/xla/stream_executor/cuda/cuda_fft.cc:607] Unable to register cuFFT factory: Attempting to register factory for plugin cuFFT when one has already been registered\n",
      "2024-01-28 09:09:11.069470: E external/local_xla/xla/stream_executor/cuda/cuda_blas.cc:1515] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered\n",
      "2024-01-28 09:09:11.074803: I tensorflow/core/platform/cpu_feature_guard.cc:182] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.\n",
      "To enable the following instructions: AVX2 FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "2024-01-28 09:09:11.646445: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Could not find TensorRT\n"
     ]
    }
   ],
   "source": [
    "import sys\n",
    "import tensorflow as tf\n",
    "sys.path.append(\"/visuworks/Blindless_AIFFELTON/Models\")\n",
    "\n",
    "# import customized modules\n",
    "import preprocess, data_generator, check_result, metrics, loss, train\n",
    "\n",
    "sys.path.append(\"/visuworks/Blindless_AIFFELTON/Models/FR_Unet\")\n",
    "import fr_unet\n",
    "\n",
    "# Insert Path\n",
    "# {model_name}_{epoch}ep_{model_inpusize}_{Generator | aG/fG/sG}\n",
    "FILE_NAME = 'sd_unet_40ep_256_sG'\n",
    "INPUT_SHAPE = (256, 256, 1)\n",
    "RESIZE_SHAPE = (512, 512, 1)\n",
    "MODEL_PATH = \"/visuworks/Blindless_AIFFELTON/Models/FR_Unet/model_parameters/\" + FILE_NAME + \".tf\"\n",
    "HISTORY_PATH = \"/visuworks/Blindless_AIFFELTON/Models/FR_Unet/history/\" + FILE_NAME + '_history' \".json\"\n",
    "SOURCE = '/visuworks/Dataset/Selected Dataset 2'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-01-28 09:09:12.806646: I external/local_xla/xla/stream_executor/cuda/cuda_executor.cc:901] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero. See more at https://github.com/torvalds/linux/blob/v6.0/Documentation/ABI/testing/sysfs-bus-pci#L344-L355\n",
      "2024-01-28 09:09:12.840086: I external/local_xla/xla/stream_executor/cuda/cuda_executor.cc:901] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero. See more at https://github.com/torvalds/linux/blob/v6.0/Documentation/ABI/testing/sysfs-bus-pci#L344-L355\n",
      "2024-01-28 09:09:12.840315: I external/local_xla/xla/stream_executor/cuda/cuda_executor.cc:901] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero. See more at https://github.com/torvalds/linux/blob/v6.0/Documentation/ABI/testing/sysfs-bus-pci#L344-L355\n",
      "2024-01-28 09:09:12.842345: I external/local_xla/xla/stream_executor/cuda/cuda_executor.cc:901] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero. See more at https://github.com/torvalds/linux/blob/v6.0/Documentation/ABI/testing/sysfs-bus-pci#L344-L355\n",
      "2024-01-28 09:09:12.842531: I external/local_xla/xla/stream_executor/cuda/cuda_executor.cc:901] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero. See more at https://github.com/torvalds/linux/blob/v6.0/Documentation/ABI/testing/sysfs-bus-pci#L344-L355\n",
      "2024-01-28 09:09:12.842700: I external/local_xla/xla/stream_executor/cuda/cuda_executor.cc:901] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero. See more at https://github.com/torvalds/linux/blob/v6.0/Documentation/ABI/testing/sysfs-bus-pci#L344-L355\n",
      "2024-01-28 09:09:12.905050: I external/local_xla/xla/stream_executor/cuda/cuda_executor.cc:901] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero. See more at https://github.com/torvalds/linux/blob/v6.0/Documentation/ABI/testing/sysfs-bus-pci#L344-L355\n",
      "2024-01-28 09:09:12.905264: I external/local_xla/xla/stream_executor/cuda/cuda_executor.cc:901] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero. See more at https://github.com/torvalds/linux/blob/v6.0/Documentation/ABI/testing/sysfs-bus-pci#L344-L355\n",
      "2024-01-28 09:09:12.905437: I external/local_xla/xla/stream_executor/cuda/cuda_executor.cc:901] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero. See more at https://github.com/torvalds/linux/blob/v6.0/Documentation/ABI/testing/sysfs-bus-pci#L344-L355\n",
      "2024-01-28 09:09:12.905550: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1929] Created device /job:localhost/replica:0/task:0/device:GPU:0 with 9902 MB memory:  -> device: 0, name: NVIDIA GeForce RTX 3080 Ti, pci bus id: 0000:43:00.0, compute capability: 8.6\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"fr_u_net\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " block (Block)               multiple                  23648     \n",
      "                                                                 \n",
      " block_1 (Block)             multiple                  42496     \n",
      "                                                                 \n",
      " block_2 (Block)             multiple                  81408     \n",
      "                                                                 \n",
      " block_3 (Block)             multiple                  81408     \n",
      "                                                                 \n",
      " block_4 (Block)             multiple                  81408     \n",
      "                                                                 \n",
      " block_5 (Block)             multiple                  37120     \n",
      "                                                                 \n",
      " block_6 (Block)             multiple                  37120     \n",
      "                                                                 \n",
      " block_7 (Block)             multiple                  146688    \n",
      "                                                                 \n",
      " block_8 (Block)             multiple                  224512    \n",
      "                                                                 \n",
      " block_9 (Block)             multiple                  380160    \n",
      "                                                                 \n",
      " block_10 (Block)            multiple                  363520    \n",
      "                                                                 \n",
      " block_11 (Block)            multiple                  363520    \n",
      "                                                                 \n",
      " block_12 (Block)            multiple                  584192    \n",
      "                                                                 \n",
      " block_13 (Block)            multiple                  829440    \n",
      "                                                                 \n",
      " block_14 (Block)            multiple                  1452032   \n",
      "                                                                 \n",
      " block_15 (Block)            multiple                  2068480   \n",
      "                                                                 \n",
      " conv2d_89 (Conv2D)          multiple                  33        \n",
      "                                                                 \n",
      " conv2d_90 (Conv2D)          multiple                  33        \n",
      "                                                                 \n",
      " conv2d_91 (Conv2D)          multiple                  33        \n",
      "                                                                 \n",
      " conv2d_92 (Conv2D)          multiple                  33        \n",
      "                                                                 \n",
      " conv2d_93 (Conv2D)          multiple                  33        \n",
      "                                                                 \n",
      " conv2d_94 (Conv2D)          multiple                  0 (unused)\n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 6797317 (25.93 MB)\n",
      "Trainable params: 6787461 (25.89 MB)\n",
      "Non-trainable params: 9856 (38.50 KB)\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "# Define custom objects for loading the model\n",
    "custom_objects = {'DiceLoss': loss.DiceLoss(), \n",
    "                  'sensitivity': metrics.sensitivity,\n",
    "                  'specificity': metrics.specificity,\n",
    "                  'accuracy' : metrics.accuracy}\n",
    "\n",
    "\n",
    "# Create augmentation\n",
    "train_preproc = preprocess.build_augmentation_for_general(RESIZE_SHAPE[0], RESIZE_SHAPE[0])\n",
    "test_preproc = preprocess.build_augmentation_for_general(RESIZE_SHAPE[0], RESIZE_SHAPE[0], is_train=False)\n",
    "\n",
    "# Create train, test generator\n",
    "train_generator = data_generator.SlicedDataGenerator(\n",
    "    SOURCE, \n",
    "    number_of_images = 2,\n",
    "    img_size=INPUT_SHAPE,\n",
    "    output_size=INPUT_SHAPE,\n",
    "    resize_shape = RESIZE_SHAPE,\n",
    "    is_train=True,\n",
    "    augmentation= train_preproc\n",
    ")\n",
    "\n",
    "test_generator = data_generator.SlicedDataGenerator(\n",
    "    SOURCE,\n",
    "    number_of_images = 2,\n",
    "    img_size=INPUT_SHAPE,\n",
    "    output_size=INPUT_SHAPE,\n",
    "    resize_shape = RESIZE_SHAPE,\n",
    "    is_train=False,\n",
    "    augmentation= test_preproc\n",
    ")\n",
    "\n",
    "# Create model\n",
    "model = fr_unet.FR_UNet(num_classes=1, feature_scale=2, dropout=0.2, fuse=True, out_ave=True)\n",
    "\n",
    "# # Input shape\n",
    "input_shape = (256, 256, 1)\n",
    "\n",
    "# # Build the model with the specified input shape\n",
    "model.build(input_shape=(None, *input_shape))\n",
    "\n",
    "# # Display the model summary\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Epoch 00001: WeightDecayScheduler setting learning rate to 9.999899747381279e-05.\n",
      "Epoch 1/40\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-01-28 09:09:24.123123: E tensorflow/core/grappler/optimizers/meta_optimizer.cc:961] layout failed: INVALID_ARGUMENT: Size of values 0 does not match size of permutation 4 @ fanin shape infr_u_net/block/conv_block/sequential/dropout/dropout/SelectV2-2-TransposeNHWCToNCHW-LayoutOptimizer\n",
      "2024-01-28 09:09:25.211034: I external/local_xla/xla/stream_executor/cuda/cuda_dnn.cc:454] Loaded cuDNN version 8904\n",
      "2024-01-28 09:09:28.135141: I external/local_xla/xla/service/service.cc:168] XLA service 0x7f71f892ecf0 initialized for platform CUDA (this does not guarantee that XLA will be used). Devices:\n",
      "2024-01-28 09:09:28.135163: I external/local_xla/xla/service/service.cc:176]   StreamExecutor device (0): NVIDIA GeForce RTX 3080 Ti, Compute Capability 8.6\n",
      "2024-01-28 09:09:28.142003: I tensorflow/compiler/mlir/tensorflow/utils/dump_mlir_util.cc:269] disabling MLIR crash reproducer, set env var `MLIR_CRASH_REPRODUCER_DIRECTORY` to enable.\n",
      "WARNING: All log messages before absl::InitializeLog() is called are written to STDERR\n",
      "I0000 00:00:1706432968.216676    4535 device_compiler.h:186] Compiled cluster using XLA!  This line is logged at most once for the lifetime of the process.\n",
      "2024-01-28 09:09:30.834580: W external/local_tsl/tsl/framework/bfc_allocator.cc:296] Allocator (GPU_0_bfc) ran out of memory trying to allocate 7.16GiB with freed_by_count=0. The caller indicates that this is not a failure, but this may mean that there could be performance gains if more memory were available.\n",
      "2024-01-28 09:09:30.895484: W external/local_tsl/tsl/framework/bfc_allocator.cc:296] Allocator (GPU_0_bfc) ran out of memory trying to allocate 7.16GiB with freed_by_count=0. The caller indicates that this is not a failure, but this may mean that there could be performance gains if more memory were available.\n",
      "2024-01-28 09:09:33.349902: W external/local_tsl/tsl/framework/bfc_allocator.cc:296] Allocator (GPU_0_bfc) ran out of memory trying to allocate 7.17GiB with freed_by_count=0. The caller indicates that this is not a failure, but this may mean that there could be performance gains if more memory were available.\n",
      "2024-01-28 09:09:33.392236: W external/local_tsl/tsl/framework/bfc_allocator.cc:296] Allocator (GPU_0_bfc) ran out of memory trying to allocate 7.17GiB with freed_by_count=0. The caller indicates that this is not a failure, but this may mean that there could be performance gains if more memory were available.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1177/1177 [==============================] - ETA: 0s - loss: 0.3623 - sensitivity: 0.6760 - specificity: 0.9627 - accuracy: 0.9430"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-01-28 09:13:01.108759: W external/local_tsl/tsl/framework/bfc_allocator.cc:296] Allocator (GPU_0_bfc) ran out of memory trying to allocate 7.51GiB with freed_by_count=0. The caller indicates that this is not a failure, but this may mean that there could be performance gains if more memory were available.\n",
      "2024-01-28 09:13:01.154833: W external/local_tsl/tsl/framework/bfc_allocator.cc:296] Allocator (GPU_0_bfc) ran out of memory trying to allocate 7.51GiB with freed_by_count=0. The caller indicates that this is not a failure, but this may mean that there could be performance gains if more memory were available.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Epoch 1: val_sensitivity improved from -inf to 0.72106, saving model to /visuworks/Blindless_AIFFELTON/Models/FR_Unet/model_parameters/sd_unet_40ep_512_sG.h5\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.10/dist-packages/keras/src/engine/training.py:3103: UserWarning: You are saving your model as an HDF5 file via `model.save()`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')`.\n",
      "  saving_api.save_model(\n"
     ]
    },
    {
     "ename": "NotImplementedError",
     "evalue": "Saving the model to HDF5 format requires the model to be a Functional model or a Sequential model. It does not work for subclassed models, because such models are defined via the body of a Python method, which isn't safely serializable. Consider saving to the Tensorflow SavedModel format (by setting save_format=\"tf\") or using `save_weights`.",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNotImplementedError\u001b[0m                       Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[3], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m \u001b[43mtrain\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mmodel_train\u001b[49m\u001b[43m(\u001b[49m\u001b[43mmodel\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m      2\u001b[0m \u001b[43m                  \u001b[49m\u001b[43mepoch\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m \u001b[49m\u001b[38;5;241;43m40\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[1;32m      3\u001b[0m \u001b[43m                  \u001b[49m\u001b[43mtrain_generator\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m \u001b[49m\u001b[43mtrain_generator\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m      4\u001b[0m \u001b[43m                  \u001b[49m\u001b[43mtest_generator\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m \u001b[49m\u001b[43mtest_generator\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m      5\u001b[0m \u001b[43m                  \u001b[49m\u001b[43mmodel_path\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m \u001b[49m\u001b[43mMODEL_PATH\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m      6\u001b[0m \u001b[43m                  \u001b[49m\u001b[43mhistory_path\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m \u001b[49m\u001b[43mHISTORY_PATH\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m/visuworks/Blindless_AIFFELTON/Models/train.py:65\u001b[0m, in \u001b[0;36mmodel_train\u001b[0;34m(model, epoch, train_generator, test_generator, model_path, history_path)\u001b[0m\n\u001b[1;32m     56\u001b[0m checkpoint \u001b[38;5;241m=\u001b[39m ModelCheckpoint(\n\u001b[1;32m     57\u001b[0m     model_path,\n\u001b[1;32m     58\u001b[0m     monitor\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mval_sensitivity\u001b[39m\u001b[38;5;124m'\u001b[39m,  \u001b[38;5;66;03m# Monitor validation sensitivity\u001b[39;00m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m     61\u001b[0m     verbose\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m1\u001b[39m\n\u001b[1;32m     62\u001b[0m )\n\u001b[1;32m     64\u001b[0m \u001b[38;5;66;03m# Train the model with the ModelCheckpoint callback\u001b[39;00m\n\u001b[0;32m---> 65\u001b[0m history \u001b[38;5;241m=\u001b[39m \u001b[43mmodel\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfit\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m     66\u001b[0m \u001b[43m    \u001b[49m\u001b[43mtrain_generator\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     67\u001b[0m \u001b[43m    \u001b[49m\u001b[43mvalidation_data\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mtest_generator\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     68\u001b[0m \u001b[43m    \u001b[49m\u001b[43msteps_per_epoch\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mlen\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mtrain_generator\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     69\u001b[0m \u001b[43m    \u001b[49m\u001b[43mepochs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mepoch\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     70\u001b[0m \u001b[43m    \u001b[49m\u001b[43mcallbacks\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m[\u001b[49m\u001b[43mweight_decay_callback\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcheckpoint\u001b[49m\u001b[43m]\u001b[49m\u001b[43m  \u001b[49m\u001b[38;5;66;43;03m# Pass the callback to the fit method\u001b[39;49;00m\n\u001b[1;32m     71\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     72\u001b[0m \u001b[38;5;66;03m# Save history to JSON file\u001b[39;00m\n\u001b[1;32m     73\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m \u001b[38;5;28mopen\u001b[39m(history_path, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mw\u001b[39m\u001b[38;5;124m'\u001b[39m) \u001b[38;5;28;01mas\u001b[39;00m json_file:\n",
      "File \u001b[0;32m/usr/local/lib/python3.10/dist-packages/keras/src/utils/traceback_utils.py:70\u001b[0m, in \u001b[0;36mfilter_traceback.<locals>.error_handler\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m     67\u001b[0m     filtered_tb \u001b[38;5;241m=\u001b[39m _process_traceback_frames(e\u001b[38;5;241m.\u001b[39m__traceback__)\n\u001b[1;32m     68\u001b[0m     \u001b[38;5;66;03m# To get the full stack trace, call:\u001b[39;00m\n\u001b[1;32m     69\u001b[0m     \u001b[38;5;66;03m# `tf.debugging.disable_traceback_filtering()`\u001b[39;00m\n\u001b[0;32m---> 70\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m e\u001b[38;5;241m.\u001b[39mwith_traceback(filtered_tb) \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[1;32m     71\u001b[0m \u001b[38;5;28;01mfinally\u001b[39;00m:\n\u001b[1;32m     72\u001b[0m     \u001b[38;5;28;01mdel\u001b[39;00m filtered_tb\n",
      "File \u001b[0;32m/usr/local/lib/python3.10/dist-packages/keras/src/saving/legacy/save.py:152\u001b[0m, in \u001b[0;36msave_model\u001b[0;34m(model, filepath, overwrite, include_optimizer, save_format, signatures, options, save_traces)\u001b[0m\n\u001b[1;32m    143\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m (\n\u001b[1;32m    144\u001b[0m     save_format \u001b[38;5;241m==\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mh5\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    145\u001b[0m     \u001b[38;5;129;01mor\u001b[39;00m (h5py \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(filepath, h5py\u001b[38;5;241m.\u001b[39mFile))\n\u001b[1;32m    146\u001b[0m     \u001b[38;5;129;01mor\u001b[39;00m saving_utils\u001b[38;5;241m.\u001b[39mis_hdf5_filepath(filepath)\n\u001b[1;32m    147\u001b[0m ):\n\u001b[1;32m    148\u001b[0m     \u001b[38;5;66;03m# TODO(b/130258301): add utility method for detecting model type.\u001b[39;00m\n\u001b[1;32m    149\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m model\u001b[38;5;241m.\u001b[39m_is_graph_network \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(\n\u001b[1;32m    150\u001b[0m         model, sequential\u001b[38;5;241m.\u001b[39mSequential\n\u001b[1;32m    151\u001b[0m     ):\n\u001b[0;32m--> 152\u001b[0m         \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mNotImplementedError\u001b[39;00m(\n\u001b[1;32m    153\u001b[0m             \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mSaving the model to HDF5 format requires the model to be a \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    154\u001b[0m             \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mFunctional model or a Sequential model. It does not work for \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    155\u001b[0m             \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124msubclassed models, because such models are defined via the \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    156\u001b[0m             \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mbody of a Python method, which isn\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mt safely serializable. \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    157\u001b[0m             \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mConsider saving to the Tensorflow SavedModel format (by \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    158\u001b[0m             \u001b[38;5;124m'\u001b[39m\u001b[38;5;124msetting save_format=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mtf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m) or using `save_weights`.\u001b[39m\u001b[38;5;124m'\u001b[39m\n\u001b[1;32m    159\u001b[0m         )\n\u001b[1;32m    160\u001b[0m     hdf5_format\u001b[38;5;241m.\u001b[39msave_model_to_hdf5(\n\u001b[1;32m    161\u001b[0m         model, filepath, overwrite, include_optimizer\n\u001b[1;32m    162\u001b[0m     )\n\u001b[1;32m    163\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n",
      "\u001b[0;31mNotImplementedError\u001b[0m: Saving the model to HDF5 format requires the model to be a Functional model or a Sequential model. It does not work for subclassed models, because such models are defined via the body of a Python method, which isn't safely serializable. Consider saving to the Tensorflow SavedModel format (by setting save_format=\"tf\") or using `save_weights`."
     ]
    }
   ],
   "source": [
    "train.model_train(model,\n",
    "                  epoch = 40,\n",
    "                  train_generator = train_generator,\n",
    "                  test_generator = test_generator,\n",
    "                  model_path = MODEL_PATH,\n",
    "                  history_path = HISTORY_PATH)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
