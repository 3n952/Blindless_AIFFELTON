{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-01-26 14:28:09.207199: I tensorflow/core/util/port.cc:113] oneDNN custom operations are on. You may see slightly different numerical results due to floating-point round-off errors from different computation orders. To turn them off, set the environment variable `TF_ENABLE_ONEDNN_OPTS=0`.\n",
      "2024-01-26 14:28:09.260235: E external/local_xla/xla/stream_executor/cuda/cuda_dnn.cc:9261] Unable to register cuDNN factory: Attempting to register factory for plugin cuDNN when one has already been registered\n",
      "2024-01-26 14:28:09.260273: E external/local_xla/xla/stream_executor/cuda/cuda_fft.cc:607] Unable to register cuFFT factory: Attempting to register factory for plugin cuFFT when one has already been registered\n",
      "2024-01-26 14:28:09.261727: E external/local_xla/xla/stream_executor/cuda/cuda_blas.cc:1515] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered\n",
      "2024-01-26 14:28:09.269609: I tensorflow/core/platform/cpu_feature_guard.cc:182] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.\n",
      "To enable the following instructions: AVX2 AVX512F AVX512_VNNI FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "2024-01-26 14:28:10.280051: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Could not find TensorRT\n"
     ]
    }
   ],
   "source": [
    "import sys\n",
    "import tensorflow as tf\n",
    "sys.path.append(\"/visuworks/Blindless_AIFFELTON/Models\")\n",
    "\n",
    "# import customized modules\n",
    "import preprocess, data_generator, check_result, metrics, loss, train\n",
    "\n",
    "sys.path.append(\"/visuworks/Blindless_AIFFELTON/Models/SD_Unet\")\n",
    "import sd_unet\n",
    "\n",
    "# Insert Path\n",
    "# {model_name}_{epoch}ep_{model_inpusize}_{Generator | aG/fG/sG}\n",
    "FILE_NAME = 'sd_unet_40ep_512_sG'\n",
    "INPUT_SHAPE = (512, 512, 1)\n",
    "RESIZE_SHAPE = (1024, 1024, 1)\n",
    "MODEL_PATH = \"/visuworks/Blindless_AIFFELTON/Models/SD_Unet/model_parameters/\" + FILE_NAME + \".h5\"\n",
    "HISTORY_PATH = \"/visuworks/Blindless_AIFFELTON/Models/SD_Unet/history/\" + FILE_NAME + '_history' \".json\"\n",
    "SOURCE = '/visuworks/Dataset/Selected Dataset 2'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-01-26 14:28:13.940656: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1929] Created device /job:localhost/replica:0/task:0/device:GPU:0 with 20763 MB memory:  -> device: 0, name: NVIDIA L4, pci bus id: 0000:00:03.0, compute capability: 8.9\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"model\"\n",
      "__________________________________________________________________________________________________\n",
      " Layer (type)                Output Shape                 Param #   Connected to                  \n",
      "==================================================================================================\n",
      " input_1 (InputLayer)        [(None, 512, 512, 1)]        0         []                            \n",
      "                                                                                                  \n",
      " conv2d (Conv2D)             (None, 512, 512, 8)          80        ['input_1[0][0]']             \n",
      "                                                                                                  \n",
      " drop_block2d (DropBlock2D)  (None, 512, 512, 8)          524288    ['conv2d[0][0]']              \n",
      "                                                                                                  \n",
      " activation (Activation)     (None, 512, 512, 8)          0         ['drop_block2d[0][0]']        \n",
      "                                                                                                  \n",
      " conv2d_1 (Conv2D)           (None, 512, 512, 8)          584       ['activation[0][0]']          \n",
      "                                                                                                  \n",
      " drop_block2d_1 (DropBlock2  (None, 512, 512, 8)          524288    ['conv2d_1[0][0]']            \n",
      " D)                                                                                               \n",
      "                                                                                                  \n",
      " activation_1 (Activation)   (None, 512, 512, 8)          0         ['drop_block2d_1[0][0]']      \n",
      "                                                                                                  \n",
      " max_pooling2d (MaxPooling2  (None, 256, 256, 8)          0         ['activation_1[0][0]']        \n",
      " D)                                                                                               \n",
      "                                                                                                  \n",
      " conv2d_2 (Conv2D)           (None, 256, 256, 16)         1168      ['max_pooling2d[0][0]']       \n",
      "                                                                                                  \n",
      " drop_block2d_2 (DropBlock2  (None, 256, 256, 16)         131072    ['conv2d_2[0][0]']            \n",
      " D)                                                                                               \n",
      "                                                                                                  \n",
      " activation_2 (Activation)   (None, 256, 256, 16)         0         ['drop_block2d_2[0][0]']      \n",
      "                                                                                                  \n",
      " conv2d_3 (Conv2D)           (None, 256, 256, 16)         2320      ['activation_2[0][0]']        \n",
      "                                                                                                  \n",
      " drop_block2d_3 (DropBlock2  (None, 256, 256, 16)         131072    ['conv2d_3[0][0]']            \n",
      " D)                                                                                               \n",
      "                                                                                                  \n",
      " activation_3 (Activation)   (None, 256, 256, 16)         0         ['drop_block2d_3[0][0]']      \n",
      "                                                                                                  \n",
      " max_pooling2d_1 (MaxPoolin  (None, 128, 128, 16)         0         ['activation_3[0][0]']        \n",
      " g2D)                                                                                             \n",
      "                                                                                                  \n",
      " conv2d_4 (Conv2D)           (None, 128, 128, 32)         4640      ['max_pooling2d_1[0][0]']     \n",
      "                                                                                                  \n",
      " drop_block2d_4 (DropBlock2  (None, 128, 128, 32)         32768     ['conv2d_4[0][0]']            \n",
      " D)                                                                                               \n",
      "                                                                                                  \n",
      " activation_4 (Activation)   (None, 128, 128, 32)         0         ['drop_block2d_4[0][0]']      \n",
      "                                                                                                  \n",
      " conv2d_5 (Conv2D)           (None, 128, 128, 32)         9248      ['activation_4[0][0]']        \n",
      "                                                                                                  \n",
      " drop_block2d_5 (DropBlock2  (None, 128, 128, 32)         32768     ['conv2d_5[0][0]']            \n",
      " D)                                                                                               \n",
      "                                                                                                  \n",
      " activation_5 (Activation)   (None, 128, 128, 32)         0         ['drop_block2d_5[0][0]']      \n",
      "                                                                                                  \n",
      " max_pooling2d_2 (MaxPoolin  (None, 64, 64, 32)           0         ['activation_5[0][0]']        \n",
      " g2D)                                                                                             \n",
      "                                                                                                  \n",
      " conv2d_6 (Conv2D)           (None, 64, 64, 64)           18496     ['max_pooling2d_2[0][0]']     \n",
      "                                                                                                  \n",
      " drop_block2d_6 (DropBlock2  (None, 64, 64, 64)           8192      ['conv2d_6[0][0]']            \n",
      " D)                                                                                               \n",
      "                                                                                                  \n",
      " activation_6 (Activation)   (None, 64, 64, 64)           0         ['drop_block2d_6[0][0]']      \n",
      "                                                                                                  \n",
      " conv2d_7 (Conv2D)           (None, 64, 64, 64)           36928     ['activation_6[0][0]']        \n",
      "                                                                                                  \n",
      " drop_block2d_7 (DropBlock2  (None, 64, 64, 64)           8192      ['conv2d_7[0][0]']            \n",
      " D)                                                                                               \n",
      "                                                                                                  \n",
      " activation_7 (Activation)   (None, 64, 64, 64)           0         ['drop_block2d_7[0][0]']      \n",
      "                                                                                                  \n",
      " conv2d_transpose (Conv2DTr  (None, 128, 128, 32)         8224      ['activation_7[0][0]']        \n",
      " anspose)                                                                                         \n",
      "                                                                                                  \n",
      " concatenate (Concatenate)   (None, 128, 128, 64)         0         ['conv2d_transpose[0][0]',    \n",
      "                                                                     'activation_5[0][0]']        \n",
      "                                                                                                  \n",
      " conv2d_8 (Conv2D)           (None, 128, 128, 32)         18464     ['concatenate[0][0]']         \n",
      "                                                                                                  \n",
      " drop_block2d_8 (DropBlock2  (None, 128, 128, 32)         32768     ['conv2d_8[0][0]']            \n",
      " D)                                                                                               \n",
      "                                                                                                  \n",
      " activation_8 (Activation)   (None, 128, 128, 32)         0         ['drop_block2d_8[0][0]']      \n",
      "                                                                                                  \n",
      " conv2d_9 (Conv2D)           (None, 128, 128, 32)         9248      ['activation_8[0][0]']        \n",
      "                                                                                                  \n",
      " drop_block2d_9 (DropBlock2  (None, 128, 128, 32)         32768     ['conv2d_9[0][0]']            \n",
      " D)                                                                                               \n",
      "                                                                                                  \n",
      " activation_9 (Activation)   (None, 128, 128, 32)         0         ['drop_block2d_9[0][0]']      \n",
      "                                                                                                  \n",
      " conv2d_transpose_1 (Conv2D  (None, 256, 256, 16)         2064      ['activation_9[0][0]']        \n",
      " Transpose)                                                                                       \n",
      "                                                                                                  \n",
      " concatenate_1 (Concatenate  (None, 256, 256, 32)         0         ['conv2d_transpose_1[0][0]',  \n",
      " )                                                                   'activation_3[0][0]']        \n",
      "                                                                                                  \n",
      " conv2d_10 (Conv2D)          (None, 256, 256, 16)         4624      ['concatenate_1[0][0]']       \n",
      "                                                                                                  \n",
      " drop_block2d_10 (DropBlock  (None, 256, 256, 16)         131072    ['conv2d_10[0][0]']           \n",
      " 2D)                                                                                              \n",
      "                                                                                                  \n",
      " activation_10 (Activation)  (None, 256, 256, 16)         0         ['drop_block2d_10[0][0]']     \n",
      "                                                                                                  \n",
      " conv2d_11 (Conv2D)          (None, 256, 256, 16)         2320      ['activation_10[0][0]']       \n",
      "                                                                                                  \n",
      " drop_block2d_11 (DropBlock  (None, 256, 256, 16)         131072    ['conv2d_11[0][0]']           \n",
      " 2D)                                                                                              \n",
      "                                                                                                  \n",
      " activation_11 (Activation)  (None, 256, 256, 16)         0         ['drop_block2d_11[0][0]']     \n",
      "                                                                                                  \n",
      " conv2d_transpose_2 (Conv2D  (None, 512, 512, 8)          520       ['activation_11[0][0]']       \n",
      " Transpose)                                                                                       \n",
      "                                                                                                  \n",
      " concatenate_2 (Concatenate  (None, 512, 512, 16)         0         ['conv2d_transpose_2[0][0]',  \n",
      " )                                                                   'activation_1[0][0]']        \n",
      "                                                                                                  \n",
      " conv2d_12 (Conv2D)          (None, 512, 512, 8)          1160      ['concatenate_2[0][0]']       \n",
      "                                                                                                  \n",
      " drop_block2d_12 (DropBlock  (None, 512, 512, 8)          524288    ['conv2d_12[0][0]']           \n",
      " 2D)                                                                                              \n",
      "                                                                                                  \n",
      " activation_12 (Activation)  (None, 512, 512, 8)          0         ['drop_block2d_12[0][0]']     \n",
      "                                                                                                  \n",
      " conv2d_13 (Conv2D)          (None, 512, 512, 8)          584       ['activation_12[0][0]']       \n",
      "                                                                                                  \n",
      " drop_block2d_13 (DropBlock  (None, 512, 512, 8)          524288    ['conv2d_13[0][0]']           \n",
      " 2D)                                                                                              \n",
      "                                                                                                  \n",
      " activation_13 (Activation)  (None, 512, 512, 8)          0         ['drop_block2d_13[0][0]']     \n",
      "                                                                                                  \n",
      " conv2d_14 (Conv2D)          (None, 512, 512, 1)          9         ['activation_13[0][0]']       \n",
      "                                                                                                  \n",
      " activation_14 (Activation)  (None, 512, 512, 1)          0         ['conv2d_14[0][0]']           \n",
      "                                                                                                  \n",
      "==================================================================================================\n",
      "Total params: 2889577 (11.02 MB)\n",
      "Trainable params: 2889577 (11.02 MB)\n",
      "Non-trainable params: 0 (0.00 Byte)\n",
      "__________________________________________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "# Define custom objects for loading the model\n",
    "custom_objects = {'DiceLoss': loss.DiceLoss(), \n",
    "                  'sensitivity': metrics.sensitivity,\n",
    "                  'specificity': metrics.specificity,\n",
    "                  'accuracy' : metrics.accuracy}\n",
    "\n",
    "\n",
    "# Create augmentation\n",
    "train_preproc = preprocess.build_augmentation_for_general(RESIZE_SHAPE[0], RESIZE_SHAPE[0])\n",
    "test_preproc = preprocess.build_augmentation_for_general(RESIZE_SHAPE[0], RESIZE_SHAPE[0], is_train=False)\n",
    "\n",
    "# Create train, test generator\n",
    "train_generator = data_generator.SlicedDataGenerator(\n",
    "    SOURCE, \n",
    "    number_of_images = 1,\n",
    "    img_size=INPUT_SHAPE,\n",
    "    output_size=INPUT_SHAPE,\n",
    "    resize_shape = RESIZE_SHAPE,\n",
    "    is_train=True,\n",
    "    augmentation= train_preproc\n",
    ")\n",
    "\n",
    "test_generator = data_generator.SlicedDataGenerator(\n",
    "    SOURCE,\n",
    "    number_of_images = 1,\n",
    "    img_size=INPUT_SHAPE,\n",
    "    output_size=INPUT_SHAPE,\n",
    "    resize_shape = RESIZE_SHAPE,\n",
    "    is_train=False,\n",
    "    augmentation= test_preproc\n",
    ")\n",
    "\n",
    "# Create model\n",
    "model = sd_unet.SD_UNet(INPUT_SHAPE)\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/40\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.10/dist-packages/tensorflow/python/util/dispatch.py:1260: UserWarning: `tf.keras.backend.random_binomial` is deprecated, and will be removed in a future version.Please use `tf.keras.backend.random_bernoulli` instead.\n",
      "  return dispatch_target(*args, **kwargs)\n",
      "2024-01-26 14:28:23.446799: I external/local_xla/xla/stream_executor/cuda/cuda_dnn.cc:454] Loaded cuDNN version 8904\n",
      "2024-01-26 14:28:26.257254: I external/local_xla/xla/service/service.cc:168] XLA service 0x7fee5a3acc80 initialized for platform CUDA (this does not guarantee that XLA will be used). Devices:\n",
      "2024-01-26 14:28:26.257292: I external/local_xla/xla/service/service.cc:176]   StreamExecutor device (0): NVIDIA L4, Compute Capability 8.9\n",
      "2024-01-26 14:28:26.263539: I tensorflow/compiler/mlir/tensorflow/utils/dump_mlir_util.cc:269] disabling MLIR crash reproducer, set env var `MLIR_CRASH_REPRODUCER_DIRECTORY` to enable.\n",
      "WARNING: All log messages before absl::InitializeLog() is called are written to STDERR\n",
      "I0000 00:00:1706279306.381934  113086 device_compiler.h:186] Compiled cluster using XLA!  This line is logged at most once for the lifetime of the process.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1177/1177 [==============================] - ETA: 0s - loss: 0.5672 - sensitivity: 0.3276 - specificity: 0.9616 - accuracy: 0.9184\n",
      "Epoch 1: val_sensitivity improved from -inf to 0.51678, saving model to /visuworks/Blindless_AIFFELTON/Models/SD_Unet/model_parameters/sd_unet_40ep_256_sG.h5\n",
      "1177/1177 [==============================] - 264s 208ms/step - loss: 0.5672 - sensitivity: 0.3276 - specificity: 0.9616 - accuracy: 0.9184 - val_loss: 0.4018 - val_sensitivity: 0.5168 - val_specificity: 0.9747 - val_accuracy: 0.9452\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.10/dist-packages/keras/src/engine/training.py:3103: UserWarning: You are saving your model as an HDF5 file via `model.save()`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')`.\n",
      "  saving_api.save_model(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 2/40\n",
      "1177/1177 [==============================] - ETA: 0s - loss: 0.4147 - sensitivity: 0.5307 - specificity: 0.9703 - accuracy: 0.9411\n",
      "Epoch 2: val_sensitivity did not improve from 0.51678\n",
      "1177/1177 [==============================] - 245s 209ms/step - loss: 0.4147 - sensitivity: 0.5307 - specificity: 0.9703 - accuracy: 0.9411 - val_loss: 0.3801 - val_sensitivity: 0.4970 - val_specificity: 0.9848 - val_accuracy: 0.9534\n",
      "Epoch 3/40\n",
      "1177/1177 [==============================] - ETA: 0s - loss: 0.3776 - sensitivity: 0.5671 - specificity: 0.9732 - accuracy: 0.9464\n",
      "Epoch 3: val_sensitivity improved from 0.51678 to 0.58560, saving model to /visuworks/Blindless_AIFFELTON/Models/SD_Unet/model_parameters/sd_unet_40ep_256_sG.h5\n",
      "1177/1177 [==============================] - 248s 210ms/step - loss: 0.3776 - sensitivity: 0.5671 - specificity: 0.9732 - accuracy: 0.9464 - val_loss: 0.3434 - val_sensitivity: 0.5856 - val_specificity: 0.9791 - val_accuracy: 0.9542\n",
      "Epoch 4/40\n",
      "1177/1177 [==============================] - ETA: 0s - loss: 0.3533 - sensitivity: 0.5934 - specificity: 0.9746 - accuracy: 0.9495\n",
      "Epoch 4: val_sensitivity did not improve from 0.58560\n",
      "1177/1177 [==============================] - 247s 209ms/step - loss: 0.3533 - sensitivity: 0.5934 - specificity: 0.9746 - accuracy: 0.9495 - val_loss: 0.3261 - val_sensitivity: 0.5854 - val_specificity: 0.9826 - val_accuracy: 0.9573\n",
      "Epoch 5/40\n",
      "1177/1177 [==============================] - ETA: 0s - loss: 0.3348 - sensitivity: 0.6148 - specificity: 0.9756 - accuracy: 0.9519\n",
      "Epoch 5: val_sensitivity improved from 0.58560 to 0.69762, saving model to /visuworks/Blindless_AIFFELTON/Models/SD_Unet/model_parameters/sd_unet_40ep_256_sG.h5\n",
      "1177/1177 [==============================] - 245s 209ms/step - loss: 0.3348 - sensitivity: 0.6148 - specificity: 0.9756 - accuracy: 0.9519 - val_loss: 0.3040 - val_sensitivity: 0.6976 - val_specificity: 0.9716 - val_accuracy: 0.9545\n",
      "Epoch 6/40\n",
      "1177/1177 [==============================] - ETA: 0s - loss: 0.3211 - sensitivity: 0.6323 - specificity: 0.9761 - accuracy: 0.9535\n",
      "Epoch 6: val_sensitivity did not improve from 0.69762\n",
      "1177/1177 [==============================] - 245s 208ms/step - loss: 0.3211 - sensitivity: 0.6323 - specificity: 0.9761 - accuracy: 0.9535 - val_loss: 0.3010 - val_sensitivity: 0.6697 - val_specificity: 0.9765 - val_accuracy: 0.9573\n",
      "Epoch 7/40\n",
      "1177/1177 [==============================] - ETA: 0s - loss: 0.3118 - sensitivity: 0.6427 - specificity: 0.9766 - accuracy: 0.9549\n",
      "Epoch 7: val_sensitivity did not improve from 0.69762\n",
      "1177/1177 [==============================] - 242s 206ms/step - loss: 0.3118 - sensitivity: 0.6427 - specificity: 0.9766 - accuracy: 0.9549 - val_loss: 0.2917 - val_sensitivity: 0.6861 - val_specificity: 0.9761 - val_accuracy: 0.9580\n",
      "Epoch 8/40\n",
      "1177/1177 [==============================] - ETA: 0s - loss: 0.3040 - sensitivity: 0.6536 - specificity: 0.9769 - accuracy: 0.9559\n",
      "Epoch 8: val_sensitivity did not improve from 0.69762\n",
      "1177/1177 [==============================] - 245s 208ms/step - loss: 0.3040 - sensitivity: 0.6536 - specificity: 0.9769 - accuracy: 0.9559 - val_loss: 0.2838 - val_sensitivity: 0.6831 - val_specificity: 0.9778 - val_accuracy: 0.9593\n",
      "Epoch 9/40\n",
      "1177/1177 [==============================] - ETA: 0s - loss: 0.2981 - sensitivity: 0.6602 - specificity: 0.9772 - accuracy: 0.9566\n",
      "Epoch 9: val_sensitivity improved from 0.69762 to 0.75076, saving model to /visuworks/Blindless_AIFFELTON/Models/SD_Unet/model_parameters/sd_unet_40ep_256_sG.h5\n",
      "1177/1177 [==============================] - 247s 210ms/step - loss: 0.2981 - sensitivity: 0.6602 - specificity: 0.9772 - accuracy: 0.9566 - val_loss: 0.2841 - val_sensitivity: 0.7508 - val_specificity: 0.9688 - val_accuracy: 0.9555\n",
      "Epoch 10/40\n",
      "1177/1177 [==============================] - ETA: 0s - loss: 0.2931 - sensitivity: 0.6692 - specificity: 0.9771 - accuracy: 0.9571\n",
      "Epoch 10: val_sensitivity did not improve from 0.75076\n",
      "1177/1177 [==============================] - 246s 209ms/step - loss: 0.2931 - sensitivity: 0.6692 - specificity: 0.9771 - accuracy: 0.9571 - val_loss: 0.2761 - val_sensitivity: 0.6848 - val_specificity: 0.9791 - val_accuracy: 0.9605\n",
      "Epoch 11/40\n",
      "1177/1177 [==============================] - ETA: 0s - loss: 0.2892 - sensitivity: 0.6733 - specificity: 0.9773 - accuracy: 0.9576\n",
      "Epoch 11: val_sensitivity did not improve from 0.75076\n",
      "1177/1177 [==============================] - 246s 209ms/step - loss: 0.2892 - sensitivity: 0.6733 - specificity: 0.9773 - accuracy: 0.9576 - val_loss: 0.2721 - val_sensitivity: 0.7013 - val_specificity: 0.9780 - val_accuracy: 0.9607\n",
      "Epoch 12/40\n",
      "1177/1177 [==============================] - ETA: 0s - loss: 0.2862 - sensitivity: 0.6779 - specificity: 0.9773 - accuracy: 0.9579\n",
      "Epoch 12: val_sensitivity did not improve from 0.75076\n",
      "1177/1177 [==============================] - 245s 209ms/step - loss: 0.2862 - sensitivity: 0.6779 - specificity: 0.9773 - accuracy: 0.9579 - val_loss: 0.2706 - val_sensitivity: 0.7253 - val_specificity: 0.9753 - val_accuracy: 0.9598\n",
      "Epoch 13/40\n",
      "1177/1177 [==============================] - ETA: 0s - loss: 0.2832 - sensitivity: 0.6828 - specificity: 0.9773 - accuracy: 0.9582\n",
      "Epoch 13: val_sensitivity did not improve from 0.75076\n",
      "1177/1177 [==============================] - 244s 207ms/step - loss: 0.2832 - sensitivity: 0.6828 - specificity: 0.9773 - accuracy: 0.9582 - val_loss: 0.2690 - val_sensitivity: 0.6893 - val_specificity: 0.9802 - val_accuracy: 0.9619\n",
      "Epoch 14/40\n",
      "1177/1177 [==============================] - ETA: 0s - loss: 0.2795 - sensitivity: 0.6868 - specificity: 0.9776 - accuracy: 0.9588\n",
      "Epoch 14: val_sensitivity did not improve from 0.75076\n",
      "1177/1177 [==============================] - 246s 209ms/step - loss: 0.2795 - sensitivity: 0.6868 - specificity: 0.9776 - accuracy: 0.9588 - val_loss: 0.2694 - val_sensitivity: 0.7425 - val_specificity: 0.9732 - val_accuracy: 0.9589\n",
      "Epoch 15/40\n",
      "1177/1177 [==============================] - ETA: 0s - loss: 0.2780 - sensitivity: 0.6896 - specificity: 0.9776 - accuracy: 0.9589\n",
      "Epoch 15: val_sensitivity did not improve from 0.75076\n",
      "1177/1177 [==============================] - 247s 210ms/step - loss: 0.2780 - sensitivity: 0.6896 - specificity: 0.9776 - accuracy: 0.9589 - val_loss: 0.2683 - val_sensitivity: 0.7381 - val_specificity: 0.9742 - val_accuracy: 0.9596\n",
      "Epoch 16/40\n",
      "1177/1177 [==============================] - ETA: 0s - loss: 0.2750 - sensitivity: 0.6931 - specificity: 0.9777 - accuracy: 0.9593\n",
      "Epoch 16: val_sensitivity did not improve from 0.75076\n",
      "1177/1177 [==============================] - 244s 207ms/step - loss: 0.2750 - sensitivity: 0.6931 - specificity: 0.9777 - accuracy: 0.9593 - val_loss: 0.2637 - val_sensitivity: 0.7108 - val_specificity: 0.9786 - val_accuracy: 0.9620\n",
      "Epoch 17/40\n",
      "1177/1177 [==============================] - ETA: 0s - loss: 0.2727 - sensitivity: 0.6964 - specificity: 0.9778 - accuracy: 0.9596\n",
      "Epoch 17: val_sensitivity did not improve from 0.75076\n",
      "1177/1177 [==============================] - 247s 210ms/step - loss: 0.2727 - sensitivity: 0.6964 - specificity: 0.9778 - accuracy: 0.9596 - val_loss: 0.2638 - val_sensitivity: 0.7427 - val_specificity: 0.9746 - val_accuracy: 0.9602\n",
      "Epoch 18/40\n",
      "1177/1177 [==============================] - ETA: 0s - loss: 0.2715 - sensitivity: 0.6986 - specificity: 0.9778 - accuracy: 0.9598\n",
      "Epoch 18: val_sensitivity did not improve from 0.75076\n",
      "1177/1177 [==============================] - 246s 209ms/step - loss: 0.2715 - sensitivity: 0.6986 - specificity: 0.9778 - accuracy: 0.9598 - val_loss: 0.2620 - val_sensitivity: 0.7360 - val_specificity: 0.9760 - val_accuracy: 0.9611\n",
      "Epoch 19/40\n",
      "1177/1177 [==============================] - ETA: 0s - loss: 0.2700 - sensitivity: 0.7007 - specificity: 0.9778 - accuracy: 0.9599\n",
      "Epoch 19: val_sensitivity did not improve from 0.75076\n",
      "1177/1177 [==============================] - 246s 209ms/step - loss: 0.2700 - sensitivity: 0.7007 - specificity: 0.9778 - accuracy: 0.9599 - val_loss: 0.2610 - val_sensitivity: 0.7493 - val_specificity: 0.9744 - val_accuracy: 0.9606\n",
      "Epoch 20/40\n",
      "1177/1177 [==============================] - ETA: 0s - loss: 0.2684 - sensitivity: 0.7033 - specificity: 0.9778 - accuracy: 0.9601\n",
      "Epoch 20: val_sensitivity improved from 0.75076 to 0.76497, saving model to /visuworks/Blindless_AIFFELTON/Models/SD_Unet/model_parameters/sd_unet_40ep_256_sG.h5\n",
      "1177/1177 [==============================] - 247s 209ms/step - loss: 0.2684 - sensitivity: 0.7033 - specificity: 0.9778 - accuracy: 0.9601 - val_loss: 0.2636 - val_sensitivity: 0.7650 - val_specificity: 0.9718 - val_accuracy: 0.9591\n",
      "Epoch 21/40\n",
      "1177/1177 [==============================] - ETA: 0s - loss: 0.2667 - sensitivity: 0.7052 - specificity: 0.9780 - accuracy: 0.9604\n",
      "Epoch 21: val_sensitivity did not improve from 0.76497\n",
      "1177/1177 [==============================] - 247s 210ms/step - loss: 0.2667 - sensitivity: 0.7052 - specificity: 0.9780 - accuracy: 0.9604 - val_loss: 0.2593 - val_sensitivity: 0.7403 - val_specificity: 0.9759 - val_accuracy: 0.9614\n",
      "Epoch 22/40\n",
      "1177/1177 [==============================] - ETA: 0s - loss: 0.2660 - sensitivity: 0.7064 - specificity: 0.9780 - accuracy: 0.9605\n",
      "Epoch 22: val_sensitivity improved from 0.76497 to 0.76771, saving model to /visuworks/Blindless_AIFFELTON/Models/SD_Unet/model_parameters/sd_unet_40ep_256_sG.h5\n",
      "1177/1177 [==============================] - 247s 210ms/step - loss: 0.2660 - sensitivity: 0.7064 - specificity: 0.9780 - accuracy: 0.9605 - val_loss: 0.2611 - val_sensitivity: 0.7677 - val_specificity: 0.9720 - val_accuracy: 0.9596\n",
      "Epoch 23/40\n",
      "1177/1177 [==============================] - ETA: 0s - loss: 0.2639 - sensitivity: 0.7092 - specificity: 0.9781 - accuracy: 0.9608\n",
      "Epoch 23: val_sensitivity did not improve from 0.76771\n",
      "1177/1177 [==============================] - 246s 209ms/step - loss: 0.2639 - sensitivity: 0.7092 - specificity: 0.9781 - accuracy: 0.9608 - val_loss: 0.2595 - val_sensitivity: 0.7594 - val_specificity: 0.9735 - val_accuracy: 0.9604\n",
      "Epoch 24/40\n",
      "1177/1177 [==============================] - ETA: 0s - loss: 0.2627 - sensitivity: 0.7111 - specificity: 0.9780 - accuracy: 0.9608\n",
      "Epoch 24: val_sensitivity did not improve from 0.76771\n",
      "1177/1177 [==============================] - 249s 212ms/step - loss: 0.2627 - sensitivity: 0.7111 - specificity: 0.9780 - accuracy: 0.9608 - val_loss: 0.2559 - val_sensitivity: 0.7346 - val_specificity: 0.9775 - val_accuracy: 0.9623\n",
      "Epoch 25/40\n",
      "1177/1177 [==============================] - ETA: 0s - loss: 0.2618 - sensitivity: 0.7125 - specificity: 0.9782 - accuracy: 0.9610\n",
      "Epoch 25: val_sensitivity did not improve from 0.76771\n",
      "1177/1177 [==============================] - 246s 209ms/step - loss: 0.2618 - sensitivity: 0.7125 - specificity: 0.9782 - accuracy: 0.9610 - val_loss: 0.2533 - val_sensitivity: 0.7356 - val_specificity: 0.9779 - val_accuracy: 0.9629\n",
      "Epoch 26/40\n",
      "1177/1177 [==============================] - ETA: 0s - loss: 0.2610 - sensitivity: 0.7145 - specificity: 0.9780 - accuracy: 0.9610\n",
      "Epoch 26: val_sensitivity did not improve from 0.76771\n",
      "1177/1177 [==============================] - 244s 207ms/step - loss: 0.2610 - sensitivity: 0.7145 - specificity: 0.9780 - accuracy: 0.9610 - val_loss: 0.2540 - val_sensitivity: 0.7475 - val_specificity: 0.9762 - val_accuracy: 0.9622\n",
      "Epoch 27/40\n",
      "1177/1177 [==============================] - ETA: 0s - loss: 0.2599 - sensitivity: 0.7153 - specificity: 0.9782 - accuracy: 0.9613\n",
      "Epoch 27: val_sensitivity did not improve from 0.76771\n",
      "1177/1177 [==============================] - 243s 207ms/step - loss: 0.2599 - sensitivity: 0.7153 - specificity: 0.9782 - accuracy: 0.9613 - val_loss: 0.2530 - val_sensitivity: 0.7344 - val_specificity: 0.9782 - val_accuracy: 0.9630\n",
      "Epoch 28/40\n",
      "1177/1177 [==============================] - ETA: 0s - loss: 0.2587 - sensitivity: 0.7175 - specificity: 0.9782 - accuracy: 0.9614\n",
      "Epoch 28: val_sensitivity improved from 0.76771 to 0.76881, saving model to /visuworks/Blindless_AIFFELTON/Models/SD_Unet/model_parameters/sd_unet_40ep_256_sG.h5\n",
      "1177/1177 [==============================] - 245s 208ms/step - loss: 0.2587 - sensitivity: 0.7175 - specificity: 0.9782 - accuracy: 0.9614 - val_loss: 0.2554 - val_sensitivity: 0.7688 - val_specificity: 0.9733 - val_accuracy: 0.9607\n",
      "Epoch 29/40\n",
      "1177/1177 [==============================] - ETA: 0s - loss: 0.2584 - sensitivity: 0.7181 - specificity: 0.9782 - accuracy: 0.9615\n",
      "Epoch 29: val_sensitivity did not improve from 0.76881\n",
      "1177/1177 [==============================] - 249s 212ms/step - loss: 0.2584 - sensitivity: 0.7181 - specificity: 0.9782 - accuracy: 0.9615 - val_loss: 0.2498 - val_sensitivity: 0.7400 - val_specificity: 0.9781 - val_accuracy: 0.9633\n",
      "Epoch 30/40\n",
      "1177/1177 [==============================] - ETA: 0s - loss: 0.2571 - sensitivity: 0.7193 - specificity: 0.9782 - accuracy: 0.9616\n",
      "Epoch 30: val_sensitivity did not improve from 0.76881\n",
      "1177/1177 [==============================] - 244s 207ms/step - loss: 0.2571 - sensitivity: 0.7193 - specificity: 0.9782 - accuracy: 0.9616 - val_loss: 0.2555 - val_sensitivity: 0.7621 - val_specificity: 0.9741 - val_accuracy: 0.9611\n",
      "Epoch 31/40\n",
      " 192/1177 [===>..........................] - ETA: 2:17 - loss: 0.2564 - sensitivity: 0.7187 - specificity: 0.9781 - accuracy: 0.9610"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[3], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m \u001b[43mtrain\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mmodel_train\u001b[49m\u001b[43m(\u001b[49m\u001b[43mmodel\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m      2\u001b[0m \u001b[43m                  \u001b[49m\u001b[43mepoch\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m \u001b[49m\u001b[38;5;241;43m40\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[1;32m      3\u001b[0m \u001b[43m                  \u001b[49m\u001b[43mtrain_generator\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m \u001b[49m\u001b[43mtrain_generator\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m      4\u001b[0m \u001b[43m                  \u001b[49m\u001b[43mtest_generator\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m \u001b[49m\u001b[43mtest_generator\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m      5\u001b[0m \u001b[43m                  \u001b[49m\u001b[43mmodel_path\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m \u001b[49m\u001b[43mMODEL_PATH\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m      6\u001b[0m \u001b[43m                  \u001b[49m\u001b[43mhistory_path\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m \u001b[49m\u001b[43mHISTORY_PATH\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m/visuworks/Blindless_AIFFELTON/Models/train.py:32\u001b[0m, in \u001b[0;36mmodel_train\u001b[0;34m(model, epoch, train_generator, test_generator, model_path, history_path)\u001b[0m\n\u001b[1;32m     23\u001b[0m checkpoint \u001b[38;5;241m=\u001b[39m ModelCheckpoint(\n\u001b[1;32m     24\u001b[0m     model_path,\n\u001b[1;32m     25\u001b[0m     monitor\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mval_sensitivity\u001b[39m\u001b[38;5;124m'\u001b[39m,  \u001b[38;5;66;03m# Monitor validation sensitivity\u001b[39;00m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m     28\u001b[0m     verbose\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m1\u001b[39m\n\u001b[1;32m     29\u001b[0m )\n\u001b[1;32m     31\u001b[0m \u001b[38;5;66;03m# Train the model with the ModelCheckpoint callback\u001b[39;00m\n\u001b[0;32m---> 32\u001b[0m history \u001b[38;5;241m=\u001b[39m \u001b[43mmodel\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfit\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m     33\u001b[0m \u001b[43m    \u001b[49m\u001b[43mtrain_generator\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     34\u001b[0m \u001b[43m    \u001b[49m\u001b[43mvalidation_data\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mtest_generator\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     35\u001b[0m \u001b[43m    \u001b[49m\u001b[43msteps_per_epoch\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mlen\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mtrain_generator\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     36\u001b[0m \u001b[43m    \u001b[49m\u001b[43mepochs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mepoch\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     37\u001b[0m \u001b[43m    \u001b[49m\u001b[43mcallbacks\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m[\u001b[49m\u001b[43mcheckpoint\u001b[49m\u001b[43m]\u001b[49m\u001b[43m  \u001b[49m\u001b[38;5;66;43;03m# Pass the callback to the fit method\u001b[39;49;00m\n\u001b[1;32m     38\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     39\u001b[0m \u001b[38;5;66;03m# Save history to JSON file\u001b[39;00m\n\u001b[1;32m     40\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m \u001b[38;5;28mopen\u001b[39m(history_path, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mw\u001b[39m\u001b[38;5;124m'\u001b[39m) \u001b[38;5;28;01mas\u001b[39;00m json_file:\n",
      "File \u001b[0;32m/usr/local/lib/python3.10/dist-packages/keras/src/utils/traceback_utils.py:65\u001b[0m, in \u001b[0;36mfilter_traceback.<locals>.error_handler\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m     63\u001b[0m filtered_tb \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[1;32m     64\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m---> 65\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mfn\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     66\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mException\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[1;32m     67\u001b[0m     filtered_tb \u001b[38;5;241m=\u001b[39m _process_traceback_frames(e\u001b[38;5;241m.\u001b[39m__traceback__)\n",
      "File \u001b[0;32m/usr/local/lib/python3.10/dist-packages/keras/src/engine/training.py:1813\u001b[0m, in \u001b[0;36mModel.fit\u001b[0;34m(self, x, y, batch_size, epochs, verbose, callbacks, validation_split, validation_data, shuffle, class_weight, sample_weight, initial_epoch, steps_per_epoch, validation_steps, validation_batch_size, validation_freq, max_queue_size, workers, use_multiprocessing)\u001b[0m\n\u001b[1;32m   1811\u001b[0m logs \u001b[38;5;241m=\u001b[39m tmp_logs\n\u001b[1;32m   1812\u001b[0m end_step \u001b[38;5;241m=\u001b[39m step \u001b[38;5;241m+\u001b[39m data_handler\u001b[38;5;241m.\u001b[39mstep_increment\n\u001b[0;32m-> 1813\u001b[0m \u001b[43mcallbacks\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mon_train_batch_end\u001b[49m\u001b[43m(\u001b[49m\u001b[43mend_step\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mlogs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1814\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mstop_training:\n\u001b[1;32m   1815\u001b[0m     \u001b[38;5;28;01mbreak\u001b[39;00m\n",
      "File \u001b[0;32m/usr/local/lib/python3.10/dist-packages/keras/src/callbacks.py:475\u001b[0m, in \u001b[0;36mCallbackList.on_train_batch_end\u001b[0;34m(self, batch, logs)\u001b[0m\n\u001b[1;32m    468\u001b[0m \u001b[38;5;250m\u001b[39m\u001b[38;5;124;03m\"\"\"Calls the `on_train_batch_end` methods of its callbacks.\u001b[39;00m\n\u001b[1;32m    469\u001b[0m \n\u001b[1;32m    470\u001b[0m \u001b[38;5;124;03mArgs:\u001b[39;00m\n\u001b[1;32m    471\u001b[0m \u001b[38;5;124;03m    batch: Integer, index of batch within the current epoch.\u001b[39;00m\n\u001b[1;32m    472\u001b[0m \u001b[38;5;124;03m    logs: Dict. Aggregated metric results up until this batch.\u001b[39;00m\n\u001b[1;32m    473\u001b[0m \u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[1;32m    474\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_should_call_train_batch_hooks:\n\u001b[0;32m--> 475\u001b[0m     \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_call_batch_hook\u001b[49m\u001b[43m(\u001b[49m\u001b[43mModeKeys\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mTRAIN\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mend\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mbatch\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mlogs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mlogs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m/usr/local/lib/python3.10/dist-packages/keras/src/callbacks.py:322\u001b[0m, in \u001b[0;36mCallbackList._call_batch_hook\u001b[0;34m(self, mode, hook, batch, logs)\u001b[0m\n\u001b[1;32m    320\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_call_batch_begin_hook(mode, batch, logs)\n\u001b[1;32m    321\u001b[0m \u001b[38;5;28;01melif\u001b[39;00m hook \u001b[38;5;241m==\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mend\u001b[39m\u001b[38;5;124m\"\u001b[39m:\n\u001b[0;32m--> 322\u001b[0m     \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_call_batch_end_hook\u001b[49m\u001b[43m(\u001b[49m\u001b[43mmode\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mbatch\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mlogs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    323\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m    324\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\n\u001b[1;32m    325\u001b[0m         \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mUnrecognized hook: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mhook\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m. \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    326\u001b[0m         \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mExpected values are [\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mbegin\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m, \u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mend\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m]\u001b[39m\u001b[38;5;124m'\u001b[39m\n\u001b[1;32m    327\u001b[0m     )\n",
      "File \u001b[0;32m/usr/local/lib/python3.10/dist-packages/keras/src/callbacks.py:345\u001b[0m, in \u001b[0;36mCallbackList._call_batch_end_hook\u001b[0;34m(self, mode, batch, logs)\u001b[0m\n\u001b[1;32m    342\u001b[0m     batch_time \u001b[38;5;241m=\u001b[39m time\u001b[38;5;241m.\u001b[39mtime() \u001b[38;5;241m-\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_batch_start_time\n\u001b[1;32m    343\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_batch_times\u001b[38;5;241m.\u001b[39mappend(batch_time)\n\u001b[0;32m--> 345\u001b[0m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_call_batch_hook_helper\u001b[49m\u001b[43m(\u001b[49m\u001b[43mhook_name\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mbatch\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mlogs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    347\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mlen\u001b[39m(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_batch_times) \u001b[38;5;241m>\u001b[39m\u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_num_batches_for_timing_check:\n\u001b[1;32m    348\u001b[0m     end_hook_name \u001b[38;5;241m=\u001b[39m hook_name\n",
      "File \u001b[0;32m/usr/local/lib/python3.10/dist-packages/keras/src/callbacks.py:393\u001b[0m, in \u001b[0;36mCallbackList._call_batch_hook_helper\u001b[0;34m(self, hook_name, batch, logs)\u001b[0m\n\u001b[1;32m    391\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m callback \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mcallbacks:\n\u001b[1;32m    392\u001b[0m     hook \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mgetattr\u001b[39m(callback, hook_name)\n\u001b[0;32m--> 393\u001b[0m     \u001b[43mhook\u001b[49m\u001b[43m(\u001b[49m\u001b[43mbatch\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mlogs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    395\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_check_timing:\n\u001b[1;32m    396\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m hook_name \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_hook_times:\n",
      "File \u001b[0;32m/usr/local/lib/python3.10/dist-packages/keras/src/callbacks.py:1093\u001b[0m, in \u001b[0;36mProgbarLogger.on_train_batch_end\u001b[0;34m(self, batch, logs)\u001b[0m\n\u001b[1;32m   1092\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mon_train_batch_end\u001b[39m(\u001b[38;5;28mself\u001b[39m, batch, logs\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mNone\u001b[39;00m):\n\u001b[0;32m-> 1093\u001b[0m     \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_batch_update_progbar\u001b[49m\u001b[43m(\u001b[49m\u001b[43mbatch\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mlogs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m/usr/local/lib/python3.10/dist-packages/keras/src/callbacks.py:1169\u001b[0m, in \u001b[0;36mProgbarLogger._batch_update_progbar\u001b[0;34m(self, batch, logs)\u001b[0m\n\u001b[1;32m   1165\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mseen \u001b[38;5;241m+\u001b[39m\u001b[38;5;241m=\u001b[39m add_seen\n\u001b[1;32m   1167\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mverbose \u001b[38;5;241m==\u001b[39m \u001b[38;5;241m1\u001b[39m:\n\u001b[1;32m   1168\u001b[0m     \u001b[38;5;66;03m# Only block async when verbose = 1.\u001b[39;00m\n\u001b[0;32m-> 1169\u001b[0m     logs \u001b[38;5;241m=\u001b[39m \u001b[43mtf_utils\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43msync_to_numpy_or_python_type\u001b[49m\u001b[43m(\u001b[49m\u001b[43mlogs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1170\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mprogbar\u001b[38;5;241m.\u001b[39mupdate(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mseen, \u001b[38;5;28mlist\u001b[39m(logs\u001b[38;5;241m.\u001b[39mitems()), finalize\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mFalse\u001b[39;00m)\n",
      "File \u001b[0;32m/usr/local/lib/python3.10/dist-packages/keras/src/utils/tf_utils.py:694\u001b[0m, in \u001b[0;36msync_to_numpy_or_python_type\u001b[0;34m(tensors)\u001b[0m\n\u001b[1;32m    691\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m t\n\u001b[1;32m    692\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m t\u001b[38;5;241m.\u001b[39mitem() \u001b[38;5;28;01mif\u001b[39;00m np\u001b[38;5;241m.\u001b[39mndim(t) \u001b[38;5;241m==\u001b[39m \u001b[38;5;241m0\u001b[39m \u001b[38;5;28;01melse\u001b[39;00m t\n\u001b[0;32m--> 694\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mtf\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mnest\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mmap_structure\u001b[49m\u001b[43m(\u001b[49m\u001b[43m_to_single_numpy_or_python_type\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtensors\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m/usr/local/lib/python3.10/dist-packages/tensorflow/python/util/nest.py:631\u001b[0m, in \u001b[0;36mmap_structure\u001b[0;34m(func, *structure, **kwargs)\u001b[0m\n\u001b[1;32m    545\u001b[0m \u001b[38;5;129m@tf_export\u001b[39m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mnest.map_structure\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m    546\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mmap_structure\u001b[39m(func, \u001b[38;5;241m*\u001b[39mstructure, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs):\n\u001b[1;32m    547\u001b[0m \u001b[38;5;250m  \u001b[39m\u001b[38;5;124;03m\"\"\"Creates a new structure by applying `func` to each atom in `structure`.\u001b[39;00m\n\u001b[1;32m    548\u001b[0m \n\u001b[1;32m    549\u001b[0m \u001b[38;5;124;03m  Refer to [tf.nest](https://www.tensorflow.org/api_docs/python/tf/nest)\u001b[39;00m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    629\u001b[0m \u001b[38;5;124;03m    ValueError: If wrong keyword arguments are provided.\u001b[39;00m\n\u001b[1;32m    630\u001b[0m \u001b[38;5;124;03m  \"\"\"\u001b[39;00m\n\u001b[0;32m--> 631\u001b[0m   \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mnest_util\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mmap_structure\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    632\u001b[0m \u001b[43m      \u001b[49m\u001b[43mnest_util\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mModality\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mCORE\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mfunc\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mstructure\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\n\u001b[1;32m    633\u001b[0m \u001b[43m  \u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m/usr/local/lib/python3.10/dist-packages/tensorflow/python/util/nest_util.py:1066\u001b[0m, in \u001b[0;36mmap_structure\u001b[0;34m(modality, func, *structure, **kwargs)\u001b[0m\n\u001b[1;32m    969\u001b[0m \u001b[38;5;250m\u001b[39m\u001b[38;5;124;03m\"\"\"Creates a new structure by applying `func` to each atom in `structure`.\u001b[39;00m\n\u001b[1;32m    970\u001b[0m \n\u001b[1;32m    971\u001b[0m \u001b[38;5;124;03m- For Modality.CORE: Refer to\u001b[39;00m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m   1063\u001b[0m \u001b[38;5;124;03m  ValueError: If wrong keyword arguments are provided.\u001b[39;00m\n\u001b[1;32m   1064\u001b[0m \u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[1;32m   1065\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m modality \u001b[38;5;241m==\u001b[39m Modality\u001b[38;5;241m.\u001b[39mCORE:\n\u001b[0;32m-> 1066\u001b[0m   \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43m_tf_core_map_structure\u001b[49m\u001b[43m(\u001b[49m\u001b[43mfunc\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mstructure\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1067\u001b[0m \u001b[38;5;28;01melif\u001b[39;00m modality \u001b[38;5;241m==\u001b[39m Modality\u001b[38;5;241m.\u001b[39mDATA:\n\u001b[1;32m   1068\u001b[0m   \u001b[38;5;28;01mreturn\u001b[39;00m _tf_data_map_structure(func, \u001b[38;5;241m*\u001b[39mstructure, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n",
      "File \u001b[0;32m/usr/local/lib/python3.10/dist-packages/tensorflow/python/util/nest_util.py:1106\u001b[0m, in \u001b[0;36m_tf_core_map_structure\u001b[0;34m(func, *structure, **kwargs)\u001b[0m\n\u001b[1;32m   1101\u001b[0m flat_structure \u001b[38;5;241m=\u001b[39m (_tf_core_flatten(s, expand_composites) \u001b[38;5;28;01mfor\u001b[39;00m s \u001b[38;5;129;01min\u001b[39;00m structure)\n\u001b[1;32m   1102\u001b[0m entries \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mzip\u001b[39m(\u001b[38;5;241m*\u001b[39mflat_structure)\n\u001b[1;32m   1104\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m _tf_core_pack_sequence_as(\n\u001b[1;32m   1105\u001b[0m     structure[\u001b[38;5;241m0\u001b[39m],\n\u001b[0;32m-> 1106\u001b[0m     [func(\u001b[38;5;241m*\u001b[39mx) \u001b[38;5;28;01mfor\u001b[39;00m x \u001b[38;5;129;01min\u001b[39;00m entries],\n\u001b[1;32m   1107\u001b[0m     expand_composites\u001b[38;5;241m=\u001b[39mexpand_composites,\n\u001b[1;32m   1108\u001b[0m )\n",
      "File \u001b[0;32m/usr/local/lib/python3.10/dist-packages/tensorflow/python/util/nest_util.py:1106\u001b[0m, in \u001b[0;36m<listcomp>\u001b[0;34m(.0)\u001b[0m\n\u001b[1;32m   1101\u001b[0m flat_structure \u001b[38;5;241m=\u001b[39m (_tf_core_flatten(s, expand_composites) \u001b[38;5;28;01mfor\u001b[39;00m s \u001b[38;5;129;01min\u001b[39;00m structure)\n\u001b[1;32m   1102\u001b[0m entries \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mzip\u001b[39m(\u001b[38;5;241m*\u001b[39mflat_structure)\n\u001b[1;32m   1104\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m _tf_core_pack_sequence_as(\n\u001b[1;32m   1105\u001b[0m     structure[\u001b[38;5;241m0\u001b[39m],\n\u001b[0;32m-> 1106\u001b[0m     [\u001b[43mfunc\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mx\u001b[49m\u001b[43m)\u001b[49m \u001b[38;5;28;01mfor\u001b[39;00m x \u001b[38;5;129;01min\u001b[39;00m entries],\n\u001b[1;32m   1107\u001b[0m     expand_composites\u001b[38;5;241m=\u001b[39mexpand_composites,\n\u001b[1;32m   1108\u001b[0m )\n",
      "File \u001b[0;32m/usr/local/lib/python3.10/dist-packages/keras/src/utils/tf_utils.py:687\u001b[0m, in \u001b[0;36msync_to_numpy_or_python_type.<locals>._to_single_numpy_or_python_type\u001b[0;34m(t)\u001b[0m\n\u001b[1;32m    684\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m_to_single_numpy_or_python_type\u001b[39m(t):\n\u001b[1;32m    685\u001b[0m     \u001b[38;5;66;03m# Don't turn ragged or sparse tensors to NumPy.\u001b[39;00m\n\u001b[1;32m    686\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(t, tf\u001b[38;5;241m.\u001b[39mTensor):\n\u001b[0;32m--> 687\u001b[0m         t \u001b[38;5;241m=\u001b[39m \u001b[43mt\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mnumpy\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    688\u001b[0m     \u001b[38;5;66;03m# Strings, ragged and sparse tensors don't have .item(). Return them\u001b[39;00m\n\u001b[1;32m    689\u001b[0m     \u001b[38;5;66;03m# as-is.\u001b[39;00m\n\u001b[1;32m    690\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(t, (np\u001b[38;5;241m.\u001b[39mndarray, np\u001b[38;5;241m.\u001b[39mgeneric)):\n",
      "File \u001b[0;32m/usr/local/lib/python3.10/dist-packages/tensorflow/python/framework/ops.py:394\u001b[0m, in \u001b[0;36m_EagerTensorBase.numpy\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    371\u001b[0m \u001b[38;5;250m\u001b[39m\u001b[38;5;124;03m\"\"\"Copy of the contents of this Tensor into a NumPy array or scalar.\u001b[39;00m\n\u001b[1;32m    372\u001b[0m \n\u001b[1;32m    373\u001b[0m \u001b[38;5;124;03mUnlike NumPy arrays, Tensors are immutable, so this method has to copy\u001b[39;00m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    391\u001b[0m \u001b[38;5;124;03m    NumPy dtype.\u001b[39;00m\n\u001b[1;32m    392\u001b[0m \u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[1;32m    393\u001b[0m \u001b[38;5;66;03m# TODO(slebedev): Consider avoiding a copy for non-CPU or remote tensors.\u001b[39;00m\n\u001b[0;32m--> 394\u001b[0m maybe_arr \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_numpy\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m  \u001b[38;5;66;03m# pylint: disable=protected-access\u001b[39;00m\n\u001b[1;32m    395\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m maybe_arr\u001b[38;5;241m.\u001b[39mcopy() \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(maybe_arr, np\u001b[38;5;241m.\u001b[39mndarray) \u001b[38;5;28;01melse\u001b[39;00m maybe_arr\n",
      "File \u001b[0;32m/usr/local/lib/python3.10/dist-packages/tensorflow/python/framework/ops.py:360\u001b[0m, in \u001b[0;36m_EagerTensorBase._numpy\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    358\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m_numpy\u001b[39m(\u001b[38;5;28mself\u001b[39m):\n\u001b[1;32m    359\u001b[0m   \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m--> 360\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_numpy_internal\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    361\u001b[0m   \u001b[38;5;28;01mexcept\u001b[39;00m core\u001b[38;5;241m.\u001b[39m_NotOkStatusException \u001b[38;5;28;01mas\u001b[39;00m e:  \u001b[38;5;66;03m# pylint: disable=protected-access\u001b[39;00m\n\u001b[1;32m    362\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m core\u001b[38;5;241m.\u001b[39m_status_to_exception(e) \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "train.model_train(model,\n",
    "                  epoch = 40,\n",
    "                  train_generator = train_generator,\n",
    "                  test_generator = test_generator,\n",
    "                  model_path = MODEL_PATH,\n",
    "                  history_path = HISTORY_PATH)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "x and y must have same first dimension, but have shapes (31,) and (30,)",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[7], line 10\u001b[0m\n\u001b[1;32m      2\u001b[0m custom_objects \u001b[38;5;241m=\u001b[39m {\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mDiceLoss\u001b[39m\u001b[38;5;124m'\u001b[39m: loss\u001b[38;5;241m.\u001b[39mDiceLoss(), \n\u001b[1;32m      3\u001b[0m                   \u001b[38;5;124m'\u001b[39m\u001b[38;5;124msensitivity\u001b[39m\u001b[38;5;124m'\u001b[39m: metrics\u001b[38;5;241m.\u001b[39msensitivity,\n\u001b[1;32m      4\u001b[0m                   \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mspecificity\u001b[39m\u001b[38;5;124m'\u001b[39m: metrics\u001b[38;5;241m.\u001b[39mspecificity,\n\u001b[1;32m      5\u001b[0m                   \u001b[38;5;124m'\u001b[39m\u001b[38;5;124maccuracy\u001b[39m\u001b[38;5;124m'\u001b[39m : metrics\u001b[38;5;241m.\u001b[39maccuracy,\n\u001b[1;32m      6\u001b[0m                   \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mDropBlock2D\u001b[39m\u001b[38;5;124m'\u001b[39m: sd_unet\u001b[38;5;241m.\u001b[39mDropBlock2D}\n\u001b[1;32m      8\u001b[0m \u001b[38;5;66;03m# Plot history and pring evaluation of test dataset\u001b[39;00m\n\u001b[1;32m      9\u001b[0m \u001b[38;5;66;03m# metrics.print_evaluation(model, test_generator)\u001b[39;00m\n\u001b[0;32m---> 10\u001b[0m \u001b[43mcheck_result\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mplot_history\u001b[49m\u001b[43m(\u001b[49m\u001b[43mHISTORY_PATH\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m/visuworks/Blindless_AIFFELTON/Models/check_result.py:196\u001b[0m, in \u001b[0;36mplot_history\u001b[0;34m(history_path)\u001b[0m\n\u001b[1;32m    193\u001b[0m plt\u001b[38;5;241m.\u001b[39mlegend()\n\u001b[1;32m    194\u001b[0m plt\u001b[38;5;241m.\u001b[39mfigure()                            \n\u001b[0;32m--> 196\u001b[0m \u001b[43mplt\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mplot\u001b[49m\u001b[43m(\u001b[49m\u001b[43mepochs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43msensitivity\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mgo\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mlabel\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43msensitivity\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[1;32m    197\u001b[0m plt\u001b[38;5;241m.\u001b[39mplot(epochs, val_sensitivity, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mg\u001b[39m\u001b[38;5;124m\"\u001b[39m, label\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mValidatin sensitivity\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m    198\u001b[0m plt\u001b[38;5;241m.\u001b[39mtitle(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124msensitivity\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n",
      "File \u001b[0;32m/usr/local/lib/python3.10/dist-packages/matplotlib/pyplot.py:3575\u001b[0m, in \u001b[0;36mplot\u001b[0;34m(scalex, scaley, data, *args, **kwargs)\u001b[0m\n\u001b[1;32m   3567\u001b[0m \u001b[38;5;129m@_copy_docstring_and_deprecators\u001b[39m(Axes\u001b[38;5;241m.\u001b[39mplot)\n\u001b[1;32m   3568\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mplot\u001b[39m(\n\u001b[1;32m   3569\u001b[0m     \u001b[38;5;241m*\u001b[39margs: \u001b[38;5;28mfloat\u001b[39m \u001b[38;5;241m|\u001b[39m ArrayLike \u001b[38;5;241m|\u001b[39m \u001b[38;5;28mstr\u001b[39m,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m   3573\u001b[0m     \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs,\n\u001b[1;32m   3574\u001b[0m ) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m \u001b[38;5;28mlist\u001b[39m[Line2D]:\n\u001b[0;32m-> 3575\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mgca\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mplot\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m   3576\u001b[0m \u001b[43m        \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   3577\u001b[0m \u001b[43m        \u001b[49m\u001b[43mscalex\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mscalex\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   3578\u001b[0m \u001b[43m        \u001b[49m\u001b[43mscaley\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mscaley\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   3579\u001b[0m \u001b[43m        \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43m{\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mdata\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mdata\u001b[49m\u001b[43m}\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mif\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mdata\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;129;43;01mis\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[38;5;129;43;01mnot\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mNone\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[38;5;28;43;01melse\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43m{\u001b[49m\u001b[43m}\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   3580\u001b[0m \u001b[43m        \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   3581\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m/usr/local/lib/python3.10/dist-packages/matplotlib/axes/_axes.py:1721\u001b[0m, in \u001b[0;36mAxes.plot\u001b[0;34m(self, scalex, scaley, data, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1478\u001b[0m \u001b[38;5;250m\u001b[39m\u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[1;32m   1479\u001b[0m \u001b[38;5;124;03mPlot y versus x as lines and/or markers.\u001b[39;00m\n\u001b[1;32m   1480\u001b[0m \n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m   1718\u001b[0m \u001b[38;5;124;03m(``'green'``) or hex strings (``'#008000'``).\u001b[39;00m\n\u001b[1;32m   1719\u001b[0m \u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[1;32m   1720\u001b[0m kwargs \u001b[38;5;241m=\u001b[39m cbook\u001b[38;5;241m.\u001b[39mnormalize_kwargs(kwargs, mlines\u001b[38;5;241m.\u001b[39mLine2D)\n\u001b[0;32m-> 1721\u001b[0m lines \u001b[38;5;241m=\u001b[39m [\u001b[38;5;241m*\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_get_lines(\u001b[38;5;28mself\u001b[39m, \u001b[38;5;241m*\u001b[39margs, data\u001b[38;5;241m=\u001b[39mdata, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)]\n\u001b[1;32m   1722\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m line \u001b[38;5;129;01min\u001b[39;00m lines:\n\u001b[1;32m   1723\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39madd_line(line)\n",
      "File \u001b[0;32m/usr/local/lib/python3.10/dist-packages/matplotlib/axes/_base.py:303\u001b[0m, in \u001b[0;36m_process_plot_var_args.__call__\u001b[0;34m(self, axes, data, *args, **kwargs)\u001b[0m\n\u001b[1;32m    301\u001b[0m     this \u001b[38;5;241m+\u001b[39m\u001b[38;5;241m=\u001b[39m args[\u001b[38;5;241m0\u001b[39m],\n\u001b[1;32m    302\u001b[0m     args \u001b[38;5;241m=\u001b[39m args[\u001b[38;5;241m1\u001b[39m:]\n\u001b[0;32m--> 303\u001b[0m \u001b[38;5;28;01myield from\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_plot_args\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    304\u001b[0m \u001b[43m    \u001b[49m\u001b[43maxes\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mthis\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mambiguous_fmt_datakey\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mambiguous_fmt_datakey\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m/usr/local/lib/python3.10/dist-packages/matplotlib/axes/_base.py:499\u001b[0m, in \u001b[0;36m_process_plot_var_args._plot_args\u001b[0;34m(self, axes, tup, kwargs, return_kwargs, ambiguous_fmt_datakey)\u001b[0m\n\u001b[1;32m    496\u001b[0m     axes\u001b[38;5;241m.\u001b[39myaxis\u001b[38;5;241m.\u001b[39mupdate_units(y)\n\u001b[1;32m    498\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m x\u001b[38;5;241m.\u001b[39mshape[\u001b[38;5;241m0\u001b[39m] \u001b[38;5;241m!=\u001b[39m y\u001b[38;5;241m.\u001b[39mshape[\u001b[38;5;241m0\u001b[39m]:\n\u001b[0;32m--> 499\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mx and y must have same first dimension, but \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    500\u001b[0m                      \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mhave shapes \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mx\u001b[38;5;241m.\u001b[39mshape\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m and \u001b[39m\u001b[38;5;132;01m{\u001b[39;00my\u001b[38;5;241m.\u001b[39mshape\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m    501\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m x\u001b[38;5;241m.\u001b[39mndim \u001b[38;5;241m>\u001b[39m \u001b[38;5;241m2\u001b[39m \u001b[38;5;129;01mor\u001b[39;00m y\u001b[38;5;241m.\u001b[39mndim \u001b[38;5;241m>\u001b[39m \u001b[38;5;241m2\u001b[39m:\n\u001b[1;32m    502\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mx and y can be no greater than 2D, but have \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    503\u001b[0m                      \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mshapes \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mx\u001b[38;5;241m.\u001b[39mshape\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m and \u001b[39m\u001b[38;5;132;01m{\u001b[39;00my\u001b[38;5;241m.\u001b[39mshape\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m)\n",
      "\u001b[0;31mValueError\u001b[0m: x and y must have same first dimension, but have shapes (31,) and (30,)"
     ]
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Define custom objects for loading the model\n",
    "custom_objects = {'DiceLoss': loss.DiceLoss(), \n",
    "                  'sensitivity': metrics.sensitivity,\n",
    "                  'specificity': metrics.specificity,\n",
    "                  'accuracy' : metrics.accuracy,\n",
    "                  'DropBlock2D': sd_unet.DropBlock2D}\n",
    "\n",
    "# Plot history and pring evaluation of test dataset\n",
    "# metrics.print_evaluation(model, test_generator)\n",
    "check_result.plot_history(HISTORY_PATH)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load the model with custom_objects parameter\n",
    "model = tf.keras.models.load_model(MODEL_PATH, custom_objects=custom_objects)\n",
    "\n",
    "# Plot model result\n",
    "num_images_to_select = 500\n",
    "check_result.visualize_SG_result(model, num_images_to_select, SOURCE, INPUT_SHAPE, test_preproc)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
